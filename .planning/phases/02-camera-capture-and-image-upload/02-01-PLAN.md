---
phase: 02-camera-capture-and-image-upload
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  # Mobile app (new)
  - mobile/package.json
  - mobile/tsconfig.json
  - mobile/babel.config.js
  - mobile/src/App.tsx
  - mobile/src/navigation/RootNavigator.tsx
  - mobile/src/navigation/types.ts
  - mobile/src/services/api.ts
  - mobile/src/services/auth.ts
  - mobile/src/services/storage.ts
  - mobile/src/store/authStore.ts
  - mobile/src/store/uiStore.ts
  - mobile/src/types/api.ts
  - mobile/src/types/photo.ts
  - mobile/src/utils/constants.ts
  - mobile/src/screens/Onboarding/WelcomeScreen.tsx
  - mobile/src/screens/Onboarding/PrePermissionScreen.tsx
  - mobile/src/screens/Onboarding/BiometricConsentScreen.tsx
  - mobile/src/screens/Auth/LoginScreen.tsx
  - mobile/src/screens/Auth/RegisterScreen.tsx
  - mobile/src/screens/Gallery/GalleryScreen.tsx
  - mobile/src/screens/Camera/CameraScreen.tsx
  # Backend (extending Phase 1)
  - backend/app/models/photo.py
  - backend/app/schemas/photo.py
  - backend/app/services/photo.py
  - backend/app/api/routes/photos.py
  - backend/app/main.py
  - backend/alembic/versions/*_add_photo_model.py
autonomous: true

must_haves:
  truths:
    - "React Native app initializes and renders a navigation stack on iOS and Android"
    - "User sees a welcome screen on first launch with 'Start capturing' button"
    - "User sees pre-permission screen explaining camera access before system dialog"
    - "User sees biometric consent screen with jurisdiction-specific text fetched from Phase 1 backend"
    - "User can log in with email/password and tokens are stored in encrypted storage"
    - "Backend accepts photo upload via presigned URL and stores metadata in database"
    - "Backend returns paginated list of user photos with thumbnail URLs"
  artifacts:
    - path: "mobile/src/App.tsx"
      provides: "Root component with React Query provider, navigation container, auth state detection"
      min_lines: 30
    - path: "mobile/src/navigation/RootNavigator.tsx"
      provides: "Conditional navigation: Onboarding -> Auth -> Main (camera + gallery) based on auth state"
      min_lines: 40
    - path: "mobile/src/services/api.ts"
      provides: "axios instance with JWT interceptor for token refresh"
      min_lines: 40
    - path: "mobile/src/services/auth.ts"
      provides: "Login, register, token refresh, logout functions using Phase 1 backend endpoints"
      min_lines: 30
    - path: "mobile/src/screens/Onboarding/BiometricConsentScreen.tsx"
      provides: "Biometric consent screen using GET /api/v1/privacy/jurisdiction and POST /api/v1/privacy/consent"
      min_lines: 40
    - path: "backend/app/models/photo.py"
      provides: "Photo SQLAlchemy model with user_id FK, s3_key, thumbnail_s3_key, dimensions, file_size"
      contains: "class Photo"
    - path: "backend/app/api/routes/photos.py"
      provides: "POST /api/v1/photos/upload (presigned URL + metadata), GET /api/v1/photos (paginated list)"
      exports: ["router"]
  key_links:
    - from: "mobile/src/services/api.ts"
      to: "backend/app/api/routes/auth.py"
      via: "axios interceptor refreshes JWT on 401"
      pattern: "api/v1/auth/refresh"
    - from: "mobile/src/screens/Onboarding/BiometricConsentScreen.tsx"
      to: "backend/app/api/routes/privacy.py"
      via: "GET /jurisdiction for consent text, POST /consent to grant"
      pattern: "api/v1/privacy"
    - from: "mobile/src/navigation/RootNavigator.tsx"
      to: "mobile/src/store/authStore.ts"
      via: "Auth state drives conditional navigation (onboarding vs auth vs main)"
      pattern: "useAuthStore"
---

<objective>
Scaffold the React Native mobile app with navigation, auth integration, and onboarding flow. Create the backend photo API for upload and gallery listing. This establishes the mobile foundation that camera capture (Plan 02) and gallery (Plan 03) build on.

Purpose: Phase 2 introduces the mobile app for the first time. This plan creates the app shell, connects it to the Phase 1 backend (auth + privacy), and builds the photo API that the upload and gallery features need.

Output:
- `mobile/` directory with React Native 0.76+ TypeScript project, navigation, auth flow, onboarding screens
- Backend Photo model, upload endpoint (presigned URL), and paginated gallery listing endpoint
- Onboarding flow: Welcome -> Pre-permission -> Biometric consent -> Auth -> Main app
</objective>

<execution_context>
@/home/jbellot/.claude/get-shit-done/workflows/execute-plan.md
@/home/jbellot/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-camera-capture-and-image-upload/02-CONTEXT.md
@.planning/phases/02-camera-capture-and-image-upload/02-RESEARCH.md

# Phase 1 summaries needed for backend integration
@.planning/phases/01-foundation-and-privacy-architecture/01-01-SUMMARY.md
@.planning/phases/01-foundation-and-privacy-architecture/01-02-SUMMARY.md
@.planning/phases/01-foundation-and-privacy-architecture/01-03-SUMMARY.md

# Key backend files to understand existing patterns
@backend/app/core/config.py
@backend/app/core/db.py
@backend/app/models/user.py
@backend/app/models/consent.py
@backend/app/api/deps.py
@backend/app/api/routes/auth.py
@backend/app/api/routes/privacy.py
@backend/app/storage/s3.py
@backend/app/main.py
@backend/app/schemas/auth.py
@backend/app/schemas/privacy.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create React Native project, navigation, auth services, and stores</name>
  <files>
    mobile/package.json
    mobile/tsconfig.json
    mobile/babel.config.js
    mobile/metro.config.js
    mobile/src/App.tsx
    mobile/src/navigation/RootNavigator.tsx
    mobile/src/navigation/types.ts
    mobile/src/services/api.ts
    mobile/src/services/auth.ts
    mobile/src/services/storage.ts
    mobile/src/store/authStore.ts
    mobile/src/store/uiStore.ts
    mobile/src/types/api.ts
    mobile/src/types/photo.ts
    mobile/src/utils/constants.ts
    mobile/src/utils/permissions.ts
    mobile/src/screens/Onboarding/WelcomeScreen.tsx
    mobile/src/screens/Onboarding/PrePermissionScreen.tsx
    mobile/src/screens/Onboarding/BiometricConsentScreen.tsx
    mobile/src/screens/Auth/LoginScreen.tsx
    mobile/src/screens/Auth/RegisterScreen.tsx
    mobile/src/screens/Gallery/GalleryScreen.tsx (placeholder)
    mobile/src/screens/Camera/CameraScreen.tsx (placeholder)
  </files>
  <action>
    **Step 1: Initialize React Native project**
    Run `npx @react-native-community/cli@latest init IrisArt --directory mobile` to create a bare React Native 0.76+ project with TypeScript (default). If the CLI prompts for options, use defaults. After init, verify `mobile/package.json` exists with react-native 0.76.x.

    **Step 2: Install all dependencies**
    From the `mobile/` directory, install:
    ```
    # Navigation
    npm install @react-navigation/native @react-navigation/native-stack react-native-screens react-native-safe-area-context

    # Camera and gestures (needed for Plan 02, install now to avoid native rebuild later)
    npm install react-native-vision-camera react-native-reanimated react-native-gesture-handler

    # Permissions and secure storage
    npm install react-native-permissions react-native-encrypted-storage @react-native-async-storage/async-storage

    # Gallery (needed for Plan 03, install now)
    npm install @shopify/flash-list react-native-fast-image

    # HTTP and state
    npm install axios @tanstack/react-query zustand
    ```

    Configure babel.config.js to include `react-native-reanimated/plugin` as the LAST plugin (required by Reanimated docs).

    **Step 3: Configure TypeScript types**
    Update `tsconfig.json` with strict mode, path aliases (`@/` -> `src/`), and module resolution for React Native.

    **Step 4: Create app constants and types**
    - `src/utils/constants.ts`: API_BASE_URL (default `http://localhost:8000/api/v1` for dev), APP_NAME, storage keys, etc.
    - `src/types/api.ts`: TypeScript types matching Phase 1 backend schemas:
      - `TokenResponse` (access_token, refresh_token, token_type)
      - `UserRead` (id, email, is_active, is_verified, created_at)
      - `ConsentRequirements` (jurisdiction, requires_explicit_consent, consent_text, etc.)
      - `JurisdictionResponse`, `ConsentGrantRequest`, `ConsentGrantResponse`
    - `src/types/photo.ts`: `Photo` type (id, user_id, s3_key, thumbnail_url, original_url, width, height, file_size, created_at), `PhotoListResponse`, `UploadPresignResponse`

    **Step 5: Create services layer**
    - `src/services/storage.ts`: Wrapper around react-native-encrypted-storage for JWT tokens and AsyncStorage for non-sensitive data (has_launched flag, onboarding_complete). Functions: `storeTokens(access, refresh)`, `getAccessToken()`, `getRefreshToken()`, `clearTokens()`, `setHasLaunched()`, `getHasLaunched()`, `setBiometricConsentGranted()`, `getBiometricConsentGranted()`.

    - `src/services/api.ts`: Create axios instance with:
      - `baseURL` from constants
      - Request interceptor: attach `Authorization: Bearer {access_token}` from encrypted storage
      - Response interceptor: on 401, attempt token refresh using stored refresh token via `POST /api/v1/auth/refresh`. If refresh succeeds, retry original request with new token. If refresh fails, clear tokens and navigate to login.
      - Export the configured axios instance as default

    - `src/services/auth.ts`: Auth service functions that call Phase 1 backend:
      - `login(email, password)` -> POST /api/v1/auth/login/json -> store tokens -> return user
      - `register(email, password)` -> POST /api/v1/auth/register -> return user
      - `logout()` -> POST /api/v1/auth/logout -> clear tokens
      - `getCurrentUser()` -> GET /api/v1/users/me -> return user
      - `refreshTokens()` -> POST /api/v1/auth/refresh -> store new tokens

    **Step 6: Create stores**
    - `src/store/authStore.ts` (zustand): `user`, `isAuthenticated`, `isLoading`, `login()`, `register()`, `logout()`, `checkAuth()` (checks stored tokens and validates with /me endpoint), `setUser()`
    - `src/store/uiStore.ts` (zustand): `isFirstLaunch`, `onboardingComplete`, `biometricConsentGranted`, `setFirstLaunch()`, `setOnboardingComplete()`, `setBiometricConsentGranted()`

    **Step 7: Create permission helpers**
    - `src/utils/permissions.ts`: Functions using react-native-permissions:
      - `checkCameraPermission()` -> returns {granted, blocked, denied}
      - `requestCameraPermission()` -> requests permission, returns result
      - Platform.select for iOS CAMERA vs Android CAMERA permission constants

    **Step 8: Create navigation structure**
    - `src/navigation/types.ts`: TypeScript navigation param types for all screens:
      - `OnboardingStackParamList`: Welcome, PrePermission, BiometricConsent
      - `AuthStackParamList`: Login, Register
      - `MainStackParamList`: Gallery, Camera, PhotoReview, PhotoDetail
      - `RootStackParamList`: Onboarding, Auth, Main

    - `src/navigation/RootNavigator.tsx`: Conditional navigation based on app state:
      - If `isFirstLaunch` and not `onboardingComplete` -> OnboardingStack (Welcome -> PrePermission -> BiometricConsent)
      - If not authenticated -> AuthStack (Login, Register)
      - If authenticated -> MainStack (Gallery as home tab, Camera, PhotoReview, PhotoDetail)
      - Use `@react-navigation/native-stack` for native performance
      - OnboardingStack flows: Welcome -> PrePermission -> BiometricConsent -> (sets onboardingComplete, navigates to Auth)
      - MainStack: Gallery is initial route, Camera accessible from Gallery via capture button

    **Step 9: Create onboarding screens**
    - `WelcomeScreen.tsx`: Single screen with app name, brief iris art description (1-2 sentences), and "Start capturing" button. Clean, minimal design. Tapping button navigates to PrePermission.

    - `PrePermissionScreen.tsx`: Explains why camera access is needed for iris photography. Shows camera icon, explanation text ("IrisVue needs camera access to capture your iris photos. We'll ask for permission next."), and "Continue" button. Tapping Continue triggers `requestCameraPermission()` from react-native-permissions, then navigates to BiometricConsent regardless of result (user can grant later).

    - `BiometricConsentScreen.tsx`: Fetches jurisdiction-specific consent from Phase 1 backend:
      1. On mount, call GET /api/v1/privacy/jurisdiction (pass device locale country_code if available via react-native's Platform/NativeModules)
      2. Display consent text from response (jurisdiction-specific: GDPR/BIPA/CCPA/GENERIC)
      3. Show scrollable consent text with "I agree" checkbox
      4. "Grant Consent" button (disabled until checkbox checked)
      5. On grant: POST /api/v1/privacy/consent with `{consent_type: "biometric_capture", jurisdiction: detected_jurisdiction, consent_text_version: "1.0"}`
      6. Note: User must be authenticated to grant consent. If not yet authenticated, store intent in uiStore and prompt consent again after login. OR: Show simplified consent text and navigate to Auth first, then show full consent on first camera access. **Decision: Navigate to Auth stack after onboarding. Check biometric consent on first camera access (before showing viewfinder). This is simpler and matches the flow: onboarding explains the app -> user creates account -> first camera tap checks consent.**
      7. So BiometricConsentScreen in onboarding is an INFORMATIONAL screen: shows what consent will be required, with "I understand, continue" button. Actual consent grant happens when user first opens camera (after being authenticated).

    **Step 10: Create auth screens**
    - `LoginScreen.tsx`: Email + password form, "Login" button, "Don't have an account? Register" link. Calls `authStore.login()`. On success, navigation automatically switches to MainStack (conditional nav). Show error messages for invalid credentials. Minimal, clean design.

    - `RegisterScreen.tsx`: Email + password + confirm password form, "Create Account" button, "Already have an account? Login" link. Calls `authStore.register()`. Shows password requirements (8+ chars, uppercase, lowercase, digit -- matching Phase 1 backend validation). On success, show "Check your email for verification" message, navigate to Login.

    **Step 11: Create placeholder screens**
    - `GalleryScreen.tsx`: Placeholder with "Gallery" title and "Capture" floating action button (navigates to Camera). Will be replaced in Plan 03.
    - `CameraScreen.tsx`: Placeholder with "Camera" title and back button. Will be replaced in Plan 02.

    **Step 12: Create root App component**
    - `src/App.tsx`: Wraps everything with:
      - `<QueryClientProvider>` (React Query)
      - `<GestureHandlerRootView>` (required by Gesture Handler)
      - `<NavigationContainer>`
      - `<RootNavigator />`
      - On mount: check auth state via `authStore.checkAuth()`, check first launch via `storage.getHasLaunched()`

    **IMPORTANT NOTES:**
    - Do NOT use Expo. This is a bare React Native project.
    - All screen components should use `StyleSheet.create()` for styles, not inline styles.
    - Use TypeScript strict mode throughout.
    - Do NOT compress photos (CONTEXT decision: upload full resolution).
    - For iOS, run `cd ios && pod install && cd ..` after all native module installations.
    - Add `react-native-reanimated/plugin` as the LAST entry in babel.config.js plugins array.
  </action>
  <verify>
    1. `cd mobile && npm install` completes without errors
    2. `npx tsc --noEmit` passes TypeScript compilation
    3. Verify all screen files exist: `ls src/screens/Onboarding/ src/screens/Auth/ src/screens/Gallery/ src/screens/Camera/`
    4. Verify services: `ls src/services/api.ts src/services/auth.ts src/services/storage.ts`
    5. Verify navigation: `ls src/navigation/RootNavigator.tsx src/navigation/types.ts`
    6. `cat babel.config.js` shows reanimated plugin as last entry
  </verify>
  <done>
    - React Native 0.76+ project exists at mobile/ with TypeScript
    - All navigation dependencies installed (react-navigation, screens, safe-area-context)
    - Camera dependencies pre-installed (vision-camera, reanimated, gesture-handler)
    - Gallery dependencies pre-installed (flash-list, fast-image)
    - HTTP/state dependencies installed (axios, react-query, zustand)
    - axios instance configured with JWT interceptor for Phase 1 backend
    - Auth service calls Phase 1 endpoints (login, register, logout, refresh, me)
    - Zustand stores manage auth state and UI state
    - Navigation conditionally renders Onboarding -> Auth -> Main based on state
    - Onboarding screens: Welcome, PrePermission, BiometricConsent (informational)
    - Auth screens: Login, Register with form validation
    - Placeholder screens for Gallery and Camera
    - TypeScript compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Create backend photo model, upload endpoint, and gallery listing API</name>
  <files>
    backend/app/models/photo.py
    backend/app/schemas/photo.py
    backend/app/services/photo.py
    backend/app/api/routes/photos.py
    backend/app/main.py
    backend/alembic/versions/*_add_photo_model.py
  </files>
  <action>
    **Step 1: Create Photo model**
    Create `backend/app/models/photo.py` following the pattern from `user.py` and `consent.py`:
    ```python
    class Photo(Base):
        __tablename__ = "photos"

        id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
        user_id = Column(UUID(as_uuid=True), ForeignKey("users.id", ondelete="CASCADE"), nullable=False, index=True)
        s3_key = Column(String, nullable=False, unique=True)  # iris/{user_id}/{uuid}.jpg
        thumbnail_s3_key = Column(String, nullable=True)  # iris/{user_id}/thumb_{uuid}.jpg (generated async)
        original_filename = Column(String, nullable=True)
        content_type = Column(String, default="image/jpeg")
        file_size = Column(BigInteger, nullable=True)  # bytes
        width = Column(Integer, nullable=True)
        height = Column(Integer, nullable=True)
        upload_status = Column(String, default="pending")  # pending, uploaded, failed
        created_at = Column(DateTime(timezone=True), server_default=func.now())
        updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())

        # Relationship
        user = relationship("User", back_populates="photos")
    ```

    Add `photos = relationship("Photo", back_populates="user", cascade="all, delete-orphan")` to User model in `backend/app/models/user.py`.

    Register Photo model in `backend/app/models/__init__.py` (create if doesn't exist).

    **Step 2: Generate Alembic migration**
    Run `cd backend && docker compose exec web alembic revision --autogenerate -m "add photo model"` to create migration.
    Apply migration: `docker compose exec web alembic upgrade head`.

    **Step 3: Create Photo schemas**
    Create `backend/app/schemas/photo.py`:
    - `PhotoRead`: id, s3_key, thumbnail_url (computed from presigned URL), original_url (computed), width, height, file_size, upload_status, created_at
    - `PhotoListResponse`: items (list of PhotoRead), total, page, page_size
    - `PresignedUploadResponse`: upload_url (presigned PUT URL), photo_id (UUID), s3_key
    - `PhotoUploadComplete`: photo_id, file_size, width, height (sent by mobile after upload completes)

    **Step 4: Create Photo service**
    Create `backend/app/services/photo.py`:
    - `create_photo_upload(db, user_id, content_type)`: Creates Photo record with status="pending", generates S3 key as `iris/{user_id}/{photo_id}.jpg`, generates presigned PUT URL (1 hour expiry) using s3_client, returns presigned URL + photo_id + s3_key.
    - `confirm_photo_upload(db, user_id, photo_id, file_size, width, height)`: Updates Photo record with status="uploaded", file_size, dimensions. Optionally generates thumbnail (defer to Phase 3 or background task).
    - `list_user_photos(db, user_id, page, page_size)`: Paginated query ordered by created_at DESC. For each photo, generates presigned GET URLs for original and thumbnail. Returns PhotoListResponse.
    - `get_photo(db, user_id, photo_id)`: Single photo with presigned URLs.
    - `delete_photo(db, user_id, photo_id)`: Deletes S3 objects and DB record.

    For presigned PUT URLs, add a `generate_presigned_put_url(key, content_type, expiry)` method to `backend/app/storage/s3.py`:
    ```python
    def generate_presigned_put_url(self, key: str, content_type: str = "image/jpeg", expiry: int = 3600) -> str:
        url = self.client.generate_presigned_url(
            "put_object",
            Params={"Bucket": self.bucket_name, "Key": key, "ContentType": content_type},
            ExpiresIn=expiry,
        )
        return url
    ```

    **Step 5: Create Photo API routes**
    Create `backend/app/api/routes/photos.py`:
    - `POST /api/v1/photos/upload` (auth required): Calls create_photo_upload, returns presigned PUT URL + photo_id. Mobile app uploads directly to S3 using this URL.
    - `POST /api/v1/photos/{photo_id}/confirm` (auth required): Mobile calls this after successful S3 upload with file_size, width, height. Marks photo as uploaded.
    - `GET /api/v1/photos` (auth required): Paginated list of user's photos (query params: page=1, page_size=20). Returns PhotoListResponse with presigned GET URLs.
    - `GET /api/v1/photos/{photo_id}` (auth required): Single photo details with presigned URLs.
    - `DELETE /api/v1/photos/{photo_id}` (auth required): Delete photo (S3 + DB).

    **Step 6: Register photos router**
    Update `backend/app/main.py` to include the photos router: `from app.api.routes import photos` and `app.include_router(photos.router)`.

    **IMPORTANT NOTES:**
    - Presigned PUT URL approach: Mobile uploads directly to S3 (not through backend). This avoids backend memory pressure for large photos (12MP+ = 5-15MB).
    - The confirm endpoint is necessary because the backend doesn't know when the S3 upload finishes. Mobile calls confirm after PUT to S3 succeeds.
    - Thumbnail generation is deferred -- for now, the gallery will use original images (FastImage handles caching/resizing on client). Phase 3 can add server-side thumbnail generation.
    - Follow existing patterns: use `get_current_active_user` dependency, async SQLAlchemy sessions, Pydantic response models.
    - User can only access their own photos (enforce user_id filter on all queries).
  </action>
  <verify>
    1. `cd backend && docker compose up -d` starts successfully
    2. `docker compose exec web alembic upgrade head` runs without errors
    3. `curl -X POST http://localhost:8000/api/v1/photos/upload -H "Authorization: Bearer {token}" -H "Content-Type: application/json"` returns presigned URL and photo_id
    4. Upload a test file to the presigned URL with `curl -X PUT "{presigned_url}" -H "Content-Type: image/jpeg" --data-binary @test.jpg`
    5. `curl -X POST http://localhost:8000/api/v1/photos/{photo_id}/confirm -H "Authorization: Bearer {token}" -H "Content-Type: application/json" -d '{"file_size": 1234, "width": 4032, "height": 3024}'` returns 200
    6. `curl http://localhost:8000/api/v1/photos -H "Authorization: Bearer {token}"` returns list with the uploaded photo
    7. `curl http://localhost:8000/docs` shows new photos endpoints in OpenAPI
  </verify>
  <done>
    - Photo model exists in database with user_id FK, s3_key, dimensions, upload_status
    - Alembic migration applied successfully
    - POST /api/v1/photos/upload returns presigned PUT URL for direct S3 upload
    - POST /api/v1/photos/{id}/confirm marks photo as uploaded with metadata
    - GET /api/v1/photos returns paginated photo list with presigned GET URLs
    - GET /api/v1/photos/{id} returns single photo details
    - DELETE /api/v1/photos/{id} removes photo from S3 and database
    - All endpoints require authentication and enforce user-scoped access
    - Presigned URLs avoid streaming large files through backend
  </done>
</task>

</tasks>

<verification>
1. Mobile project builds: `cd mobile && npx tsc --noEmit` passes
2. Backend starts: `cd backend && docker compose up -d` succeeds
3. Backend migration applied: `docker compose exec web alembic current` shows latest migration
4. Photo upload flow works end-to-end: request presigned URL -> upload to S3 -> confirm -> list shows photo
5. Auth flow: mobile auth service can call Phase 1 backend login endpoint and receive JWT
6. Navigation structure: RootNavigator correctly switches between Onboarding/Auth/Main stacks
</verification>

<success_criteria>
- React Native 0.76+ app exists at `mobile/` with TypeScript, all dependencies installed
- Navigation conditionally shows Onboarding -> Auth -> Main based on app state
- Onboarding screens implemented: Welcome, PrePermission, BiometricConsent (informational)
- Auth screens connect to Phase 1 backend with JWT token management
- Backend Photo model and API support presigned upload + paginated listing
- TypeScript compiles without errors in mobile project
</success_criteria>

<output>
After completion, create `.planning/phases/02-camera-capture-and-image-upload/02-01-SUMMARY.md`
</output>
