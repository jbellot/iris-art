---
phase: 03-ai-processing-pipeline
plan: 03
type: execute
wave: 3
depends_on: ["03-01", "03-02"]
files_modified:
  - mobile/src/services/processing.ts
  - mobile/src/hooks/useJobProgress.ts
  - mobile/src/hooks/useProcessing.ts
  - mobile/src/store/processingStore.ts
  - mobile/src/types/processing.ts
  - mobile/src/screens/Gallery/GalleryScreen.tsx
  - mobile/src/screens/Gallery/PhotoDetailScreen.tsx
  - mobile/src/screens/Processing/ProcessingResultScreen.tsx
  - mobile/src/components/Gallery/PhotoThumbnail.tsx
  - mobile/src/components/Gallery/ProcessingBadge.tsx
  - mobile/src/components/Processing/BeforeAfterSlider.tsx
  - mobile/src/navigation/RootNavigator.tsx
  - mobile/src/navigation/types.ts
autonomous: false

must_haves:
  truths:
    - "User taps Process button on a captured photo and sees processing start"
    - "User sees real-time progress with step names on gallery thumbnail during processing"
    - "User can navigate freely while processing runs in background"
    - "User sees before/after slider comparing original and processed result"
    - "User can save processed result to device, share externally, and reprocess"
    - "User sees friendly error with suggestion when processing fails"
    - "User can select multiple photos and queue them all for batch processing"
  artifacts:
    - path: "mobile/src/services/processing.ts"
      provides: "Processing API client for job submission, status, batch, reprocess"
      contains: "submitProcessing"
    - path: "mobile/src/hooks/useJobProgress.ts"
      provides: "WebSocket hook for real-time job progress"
      contains: "useJobProgress"
    - path: "mobile/src/screens/Processing/ProcessingResultScreen.tsx"
      provides: "Result screen with before/after slider, metadata, actions"
      contains: "ProcessingResultScreen"
    - path: "mobile/src/components/Processing/BeforeAfterSlider.tsx"
      provides: "Before/after image comparison slider component"
      contains: "BeforeAfterSlider"
    - path: "mobile/src/store/processingStore.ts"
      provides: "Zustand store for tracking active processing jobs"
      contains: "useProcessingStore"
  key_links:
    - from: "mobile/src/services/processing.ts"
      to: "backend /api/v1/processing/*"
      via: "axios API calls"
      pattern: "api\\.(post|get).*processing"
    - from: "mobile/src/hooks/useJobProgress.ts"
      to: "backend /ws/jobs/{job_id}"
      via: "WebSocket connection"
      pattern: "new WebSocket"
    - from: "mobile/src/screens/Gallery/GalleryScreen.tsx"
      to: "mobile/src/store/processingStore.ts"
      via: "Zustand store subscription"
      pattern: "useProcessingStore"
    - from: "mobile/src/screens/Processing/ProcessingResultScreen.tsx"
      to: "mobile/src/components/Processing/BeforeAfterSlider.tsx"
      via: "Component composition"
      pattern: "BeforeAfterSlider"
---

<objective>
Build the mobile processing UX: Process button on photos, real-time progress on gallery thumbnails via WebSocket, processing result screen with before/after slider, save/share/reprocess actions, batch processing support, and friendly error handling.

Purpose: This is the user-facing experience for Phase 3. Without this, the AI pipeline runs but the user cannot interact with it. The before/after slider is the "hero interaction" per user decision.

Output: Complete mobile flow from tapping "Process" on a photo through seeing the beautiful result with a before/after comparison slider.
</objective>

<execution_context>
@/home/jbellot/.claude/get-shit-done/workflows/execute-plan.md
@/home/jbellot/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-processing-pipeline/03-RESEARCH.md
@.planning/phases/03-ai-processing-pipeline/03-01-SUMMARY.md
@.planning/phases/03-ai-processing-pipeline/03-02-SUMMARY.md
@.planning/phases/02-camera-capture-and-image-upload/02-01-SUMMARY.md

Key existing mobile infrastructure:
- Navigation: mobile/src/navigation/RootNavigator.tsx (MainStack with Gallery, PhotoDetail, Camera, PhotoReview)
- Gallery: mobile/src/screens/Gallery/GalleryScreen.tsx (FlashList masonry, upload progress overlay)
- PhotoDetail: mobile/src/screens/Gallery/PhotoDetailScreen.tsx (full-screen with pinch-to-zoom, delete)
- API client: mobile/src/services/api.ts (axios with JWT interceptor)
- Upload store: mobile/src/hooks/useUpload.ts (Zustand, pattern to follow for processing store)
- Photo types: mobile/src/types/photo.ts
- Constants: mobile/src/utils/constants.ts (API_BASE_URL, WS_BASE_URL)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Processing service, WebSocket hook, Zustand store, and gallery integration</name>
  <files>
    mobile/src/types/processing.ts
    mobile/src/services/processing.ts
    mobile/src/hooks/useJobProgress.ts
    mobile/src/hooks/useProcessing.ts
    mobile/src/store/processingStore.ts
    mobile/src/screens/Gallery/GalleryScreen.tsx
    mobile/src/screens/Gallery/PhotoDetailScreen.tsx
    mobile/src/components/Gallery/PhotoThumbnail.tsx
    mobile/src/components/Gallery/ProcessingBadge.tsx
    mobile/src/utils/constants.ts
  </files>
  <action>
    **1. Create processing types** at `mobile/src/types/processing.ts`:
    ```typescript
    export interface ProcessingJob {
      job_id: string;
      photo_id: string;
      status: 'pending' | 'processing' | 'completed' | 'failed';
      current_step: string | null;
      progress: number;
      error_type: 'quality_issue' | 'transient_error' | 'server_error' | null;
      error_message: string | null;
      suggestion: string | null;
      result_url: string | null;
      original_url: string | null;
      processing_time_ms: number | null;
      result_width: number | null;
      result_height: number | null;
      websocket_url: string;
      created_at: string;
    }

    export interface ProcessingProgress {
      job_id: string;
      status: string;
      progress: number;
      step: string;  // User-facing magical name
      timestamp: string;
      // Completion fields (only present when completed)
      result_url?: string;
      processing_time_ms?: number;
      result_width?: number;
      result_height?: number;
      // Error fields (only present when failed)
      error_type?: string;
      message?: string;
      suggestion?: string;
    }
    ```

    **2. Add WS_BASE_URL constant** to `mobile/src/utils/constants.ts`:
    - Add `export const WS_BASE_URL = 'ws://10.0.2.2:8000';` (Android emulator to host)
    - Also define `export const WS_BASE_URL_IOS = 'ws://localhost:8000';`
    - Use Platform.OS to select appropriate URL, or just use the API_BASE_URL with ws:// protocol substitution

    **3. Create processing API service** at `mobile/src/services/processing.ts`:
    - `submitProcessing(photoId: string): Promise<ProcessingJob>` - POST /api/v1/processing/submit
    - `submitBatchProcessing(photoIds: string[]): Promise<ProcessingJob[]>` - POST /api/v1/processing/batch
    - `getJobStatus(jobId: string): Promise<ProcessingJob>` - GET /api/v1/processing/jobs/{jobId}
    - `getUserJobs(page?: number): Promise<{items: ProcessingJob[], total: number}>` - GET /api/v1/processing/jobs
    - `reprocessJob(jobId: string): Promise<ProcessingJob>` - POST /api/v1/processing/jobs/{jobId}/reprocess
    - Use existing `api` axios instance (JWT interceptor handles auth)

    **4. Create WebSocket hook** at `mobile/src/hooks/useJobProgress.ts`:
    - `useJobProgress(jobId: string | null)` hook
    - Returns: `{ progress, step, status, result, error, isConnected }`
    - Opens WebSocket to `${WS_BASE_URL}/ws/jobs/${jobId}?token=${accessToken}`
    - Get access token from storage (import getAccessToken from services/storage)
    - On message: parse JSON, update state (progress, step name, status)
    - On 'completed' status: store result (result_url, dimensions, processing_time_ms), close WebSocket
    - On 'failed' status: store error (error_type, message, suggestion), close WebSocket
    - On error/close: set isConnected=false. If job not completed/failed, attempt reconnect after 2 seconds (max 3 retries)
    - Cleanup: close WebSocket on unmount or when jobId changes
    - If jobId is null, do nothing (no WebSocket connection)

    **5. Create processing Zustand store** at `mobile/src/store/processingStore.ts`:
    - Tracks all active processing jobs (similar pattern to useUploadStore from Phase 2)
    - State: `jobs: Map<string, { jobId: string, photoId: string, status, progress, step, error, result }>`
    - Actions:
      - `addJob(jobId, photoId)`: Add job to tracking
      - `updateJob(jobId, updates)`: Update job progress/status
      - `removeJob(jobId)`: Remove completed/failed job from tracking
      - `getJobForPhoto(photoId)`: Get active job for a specific photo
      - `getAllJobs()`: Get all tracked jobs
      - `getActiveJobs()`: Get jobs that are pending or processing
    - Subscribe to WebSocket updates via useJobProgress (the hook updates the store)

    **6. Create useProcessing hook** at `mobile/src/hooks/useProcessing.ts`:
    - Combines processing service with store management
    - `startProcessing(photoId: string)`: Calls API, adds to store, returns jobId
    - `startBatchProcessing(photoIds: string[])`: Calls batch API, adds all to store
    - `reprocess(jobId: string)`: Calls reprocess API, adds new job to store
    - Invalidates React Query photos cache on job completion

    **7. Create ProcessingBadge component** at `mobile/src/components/Gallery/ProcessingBadge.tsx`:
    - Small overlay badge for gallery thumbnails showing processing state
    - States:
      - **Processing:** Animated circular progress ring with percentage, step name below
      - **Completed:** Small checkmark icon (green)
      - **Failed:** Small X icon (red) with "Tap to retry" text
    - Uses Animated API for smooth progress ring animation
    - Claude's discretion on design: Use a semi-transparent dark overlay with a circular progress indicator

    **8. Update PhotoThumbnail component** at `mobile/src/components/Gallery/PhotoThumbnail.tsx`:
    - Accept new optional prop: `processingJob?: ProcessingJobState`
    - If processingJob exists and status is processing/pending: show ProcessingBadge overlay
    - If processingJob exists and status is completed: show small completed badge
    - If processingJob exists and status is failed: show failed badge

    **9. Update GalleryScreen** at `mobile/src/screens/Gallery/GalleryScreen.tsx`:
    - Import useProcessingStore
    - For each photo in the gallery, check if there is an active processing job
    - Pass processing job state to PhotoThumbnail
    - Add "Process" button functionality: long-press on a photo opens action sheet with "Process" option
    - OR: Add a "Process" button in the PhotoDetail screen (more natural UX -- user opens photo, taps Process)
    - For batch: Add multi-select mode (long-press to enter, tap to select/deselect, "Process All" FAB)

    **10. Update PhotoDetailScreen** at `mobile/src/screens/Gallery/PhotoDetailScreen.tsx`:
    - Add "Process" button in the header (magic wand icon or "Process" text button)
    - If photo has an active processing job: show progress indicator instead of Process button
    - If photo has a completed processing job: show "View Result" button that navigates to ProcessingResultScreen
    - On "Process" tap: call startProcessing(photoId), show progress indicator
    - Add processing state tracking using useProcessingStore
  </action>
  <verify>
    cd mobile && npx tsc --noEmit  # TypeScript compiles
    grep "submitProcessing" mobile/src/services/processing.ts  # API service exists
    grep "useJobProgress" mobile/src/hooks/useJobProgress.ts  # WebSocket hook exists
    grep "useProcessingStore" mobile/src/store/processingStore.ts  # Store exists
    grep "ProcessingBadge" mobile/src/components/Gallery/ProcessingBadge.tsx  # Badge exists
    grep "Process" mobile/src/screens/Gallery/PhotoDetailScreen.tsx  # Process button exists
  </verify>
  <done>
    Processing API service calls all backend endpoints. WebSocket hook receives real-time progress updates. Zustand store tracks all active jobs. Gallery thumbnails show processing state (progress ring, checkmark, failed indicator). PhotoDetail screen has Process button that starts processing and shows live progress. Batch processing via multi-select in gallery.
  </done>
</task>

<task type="auto">
  <name>Task 2: Processing result screen with before/after slider and actions</name>
  <files>
    mobile/src/screens/Processing/ProcessingResultScreen.tsx
    mobile/src/components/Processing/BeforeAfterSlider.tsx
    mobile/src/navigation/RootNavigator.tsx
    mobile/src/navigation/types.ts
  </files>
  <action>
    **1. Update navigation types** at `mobile/src/navigation/types.ts`:
    - Add to MainStackParamList:
      ```typescript
      ProcessingResult: {
        jobId: string;
        photoId: string;
      };
      ```

    **2. Create BeforeAfterSlider component** at `mobile/src/components/Processing/BeforeAfterSlider.tsx`:
    - **This is the hero interaction** per user decision
    - Full-width image comparison slider
    - Left side: original captured photo
    - Right side: processed iris result
    - Draggable divider line in the center
    - Implementation:
      - Use PanResponder or GestureDetector for drag handling
      - Two FastImage components, same dimensions
      - Right image is clipped using `overflow: 'hidden'` and dynamic width based on slider position
      - Vertical divider line (2px white) with small circular handle at center
      - Slider position stored as Animated.Value (0 to image width)
      - Default position: center (50%)
      - Labels: "Before" (left) and "After" (right) in subtle text
    - Props: `originalUrl: string`, `processedUrl: string`, `width: number`, `height: number`
    - Use FastImage with immutable caching (same pattern as PhotoDetail)

    **3. Create ProcessingResultScreen** at `mobile/src/screens/Processing/ProcessingResultScreen.tsx`:
    - Route params: jobId, photoId
    - Fetch job status from API (or use cached data from store)
    - **Layout:**
      - Full-screen dark background
      - Header with back button and share button
      - BeforeAfterSlider (hero, takes most of screen)
      - Metadata bar below slider:
        - Resolution: "{width} x {height}"
        - Processing time: "{N}s" (convert from ms)
      - Action buttons row at bottom:
        - **Save to Device:** Use React Native CameraRoll or MediaLibrary to save processed image
          - Download processed image from presigned URL
          - Save to device camera roll/gallery
          - Show success toast
        - **Share:** Use React Native Share API
          - Share processed image URL (or download and share file)
        - **Reprocess:** Call reprocessJob, navigate back to PhotoDetail to see new progress
    - **Error state:** If job is failed, show error screen instead:
      - Friendly error message (from job.error_message)
      - Suggestion text (from job.suggestion)
      - If quality_issue: "Recapture" button linking to Camera screen
      - If transient_error/server_error: "Try Again" button calling reprocess
    - **Loading state:** If job is still processing (user navigated directly), show progress with step name

    **4. Register ProcessingResult screen** in `mobile/src/navigation/RootNavigator.tsx`:
    - Add ProcessingResult screen to MainStack navigator
    - Header hidden (screen has custom header)

    **5. Wire navigation from PhotoDetailScreen:**
    - When user taps "View Result" on a photo with completed processing job, navigate to ProcessingResult with jobId and photoId
    - When processing completes while user is on PhotoDetailScreen, automatically show "View Result" button

    **Important user decisions to honor:**
    - Before/after slider is the HERO interaction
    - Show final result only -- no intermediate steps exposed to user
    - Minimal metadata: resolution and processing time only
    - Actions: Save to device, Share externally, Reprocess
    - Friendly error tone with actionable suggestions
    - Quality failures suggest recapturing with link to camera
  </action>
  <verify>
    cd mobile && npx tsc --noEmit  # TypeScript compiles
    grep "BeforeAfterSlider" mobile/src/components/Processing/BeforeAfterSlider.tsx  # Component exists
    grep "ProcessingResultScreen" mobile/src/screens/Processing/ProcessingResultScreen.tsx  # Screen exists
    grep "ProcessingResult" mobile/src/navigation/types.ts  # Navigation type added
    grep "ProcessingResult" mobile/src/navigation/RootNavigator.tsx  # Screen registered
    grep "Save" mobile/src/screens/Processing/ProcessingResultScreen.tsx  # Save action exists
    grep "Share" mobile/src/screens/Processing/ProcessingResultScreen.tsx  # Share action exists
    grep "Reprocess" mobile/src/screens/Processing/ProcessingResultScreen.tsx  # Reprocess action exists
  </verify>
  <done>
    ProcessingResultScreen shows before/after slider as hero interaction, minimal metadata (resolution, processing time), and three actions (Save to Device, Share, Reprocess). Error states show friendly messages with actionable suggestions and links to camera for quality issues. Navigation integrated with PhotoDetail and gallery flow.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify complete processing flow on device</name>
  <files>mobile/src/screens/Processing/ProcessingResultScreen.tsx</files>
  <action>
    This is a human verification checkpoint. Claude has built the complete Phase 3 AI processing pipeline:
    - Backend: ProcessingJob model, AI pipeline (segmentation + reflection removal + enhancement), Celery workers with priority queues, processing API, WebSocket progress streaming
    - Mobile: Process button on PhotoDetail, real-time progress on gallery thumbnails, WebSocket progress hook, before/after result slider, save/share/reprocess actions, batch processing, error handling with friendly messages

    No further code changes needed. User verifies the flow on device.
  </action>
  <verify>
    **Prerequisites:**
    1. Start backend: `cd backend && docker compose up -d`
    2. Run migrations: `cd backend && alembic upgrade head`
    3. Start Metro: `cd mobile && npx react-native start`
    4. Build and run app on device/emulator

    **Test 1: Single photo processing**
    1. Open gallery, tap a captured photo to open detail view
    2. Tap "Process" button
    3. Verify: Job starts, progress indicator appears on PhotoDetail screen
    4. Return to gallery -- verify processing badge on thumbnail (progress ring with step name)
    5. Wait for completion -- verify badge changes to checkmark
    6. Tap processed photo, tap "View Result"
    7. Verify: Before/after slider works (drag divider left and right)
    8. Verify: Metadata shows resolution and processing time
    9. Verify: Save to Device, Share, Reprocess buttons are present

    **Test 2: Batch processing**
    1. Long-press to enter multi-select in gallery
    2. Select 2-3 photos, tap "Process All"
    3. Verify: All selected photos show processing badges
    4. Verify: Results arrive independently as each completes

    **Test 3: Background processing**
    1. Start processing a photo
    2. Navigate to Camera screen (or any other screen)
    3. Return to Gallery
    4. Verify: Processing continued in background, progress updated

    **Test 4: Error handling (if possible to trigger)**
    1. Verify error messages are friendly (not technical stack traces)
    2. Verify "Reprocess" button works on failed jobs

    Note: AI model quality depends on model weights being present. In dev mode (no model weights), simulated segmentation and OpenCV fallbacks are used -- the pipeline works but output quality is placeholder.
  </verify>
  <done>
    User has verified: single photo processing works end-to-end, before/after slider is interactive, batch processing queues multiple photos, background processing continues while navigating, error messages are friendly. Type "approved" or describe any issues found.
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles without errors (npx tsc --noEmit)
2. Processing service calls all backend endpoints correctly
3. WebSocket hook connects and receives progress updates
4. Gallery thumbnails show processing state
5. Before/after slider is draggable and shows both images
6. Save to device downloads and saves processed image
7. Share opens system share sheet
8. Reprocess creates new job
9. Error states show friendly messages with suggestions
10. Batch processing queues multiple photos
</verification>

<success_criteria>
- User taps Process on PhotoDetail and sees real-time progress with step names
- Gallery thumbnails show processing badge (progress ring during processing, checkmark on completion)
- Result screen has before/after slider as hero interaction
- Metadata shows resolution and processing time below slider
- Save, Share, Reprocess actions work from result screen
- Failed processing shows friendly error with suggestion and retry/recapture option
- User can navigate freely during processing (not locked to any screen)
- Batch processing queues multiple photos from gallery multi-select
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-processing-pipeline/03-03-SUMMARY.md`
</output>
