---
phase: 03-ai-processing-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - backend/app/api/routes/websocket.py
  - backend/app/schemas/websocket.py
  - backend/app/main.py
  - backend/app/workers/tasks/processing.py
autonomous: true

must_haves:
  truths:
    - "User receives real-time progress updates during AI processing via WebSocket"
    - "Progress updates show magical step names (Finding your iris... Removing reflections... Enhancing quality...)"
    - "WebSocket delivers final result URL when processing completes"
    - "WebSocket delivers classified error with friendly message and suggestion when processing fails"
    - "Job continues processing in background if WebSocket disconnects"
  artifacts:
    - path: "backend/app/api/routes/websocket.py"
      provides: "WebSocket endpoint for real-time job progress streaming"
      contains: "job_progress_websocket"
    - path: "backend/app/schemas/websocket.py"
      provides: "Pydantic schemas for WebSocket message types"
      contains: "ProgressMessage"
  key_links:
    - from: "backend/app/api/routes/websocket.py"
      to: "backend/app/workers/celery_app.py"
      via: "AsyncResult polling"
      pattern: "AsyncResult.*celery_app"
    - from: "backend/app/api/routes/websocket.py"
      to: "backend/app/services/processing.py"
      via: "Job status lookup"
      pattern: "get_job"
---

<objective>
Implement WebSocket real-time progress streaming for processing jobs, with magical user-facing step names, error classification with friendly messages, and reliable delivery even across connection interruptions.

Purpose: Users need to see what is happening during AI processing. A static spinner is insufficient -- the user should see "Finding your iris...", "Removing reflections...", "Enhancing quality..." as processing progresses. This is a locked user decision.

Output: WebSocket endpoint that streams progress updates from Celery task state to connected mobile clients, with proper error handling and graceful disconnection.
</objective>

<execution_context>
@/home/jbellot/.claude/get-shit-done/workflows/execute-plan.md
@/home/jbellot/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ai-processing-pipeline/03-RESEARCH.md
@.planning/phases/03-ai-processing-pipeline/03-01-SUMMARY.md

Key existing infrastructure from Plan 03-01:
- ProcessingJob model with status, current_step, progress, error_type, error_message, suggestion
- process_iris_pipeline Celery task with update_state calls
- Processing API at /api/v1/processing/*
- Celery app with priority queues
</context>

<tasks>

<task type="auto">
  <name>Task 1: WebSocket progress endpoint with step name mapping</name>
  <files>
    backend/app/api/routes/websocket.py
    backend/app/schemas/websocket.py
    backend/app/main.py
  </files>
  <action>
    **1. Create WebSocket message schemas** at `backend/app/schemas/websocket.py`:
    - `ProgressMessage`: job_id, status (pending|processing|completed|failed), progress (0-100), step (str, user-facing name), timestamp (ISO 8601)
    - `CompletionMessage`: extends ProgressMessage with result_url (presigned), processing_time_ms, result_width, result_height
    - `ErrorMessage`: extends ProgressMessage with error_type, message (friendly), suggestion (nullable)
    - These are for documentation/typing only -- WebSocket sends raw dicts via send_json

    **2. Create step name mapping** -- Map internal step names to magical, user-facing names per user decision:
    ```python
    STEP_DISPLAY_NAMES = {
        'loading': 'Preparing your image...',
        'segmenting': 'Finding your iris...',
        'removing_reflections': 'Removing reflections...',
        'enhancing': 'Enhancing quality...',
        'saving': 'Almost done...',
    }
    ```
    Per user decision: "Magic feel" -- minimal technical explanation, keep names magical not clinical.

    **3. Create WebSocket endpoint** at `backend/app/api/routes/websocket.py`:
    - `GET /ws/jobs/{job_id}` WebSocket endpoint
    - **Authentication:** Accept JWT token as query parameter (`?token=...`) since WebSocket doesn't support Authorization header in the same way. Validate token using same logic as get_current_user but extracting from query param.
    - **Connection flow:**
      1. Accept WebSocket connection
      2. Validate JWT token from query param
      3. Look up job in database, verify job belongs to authenticated user
      4. Enter polling loop
    - **Polling loop** (every 500ms):
      - Get Celery task result via `AsyncResult(job_id, app=celery_app)`
      - Also read job from database (for persistent state after task completion)
      - Map current_step to display name using STEP_DISPLAY_NAMES
      - Send progress message: `{job_id, status, progress, step: display_name, timestamp}`
      - If task completed: send completion message with result_url (generate presigned URL from result_s3_key), processing_time_ms, dimensions. Then close.
      - If task failed: send error message with error_type, friendly message, suggestion. Then close.
      - If WebSocket disconnects (WebSocketDisconnect exception): silently exit. Job continues in Celery.
    - **Fallback for missed updates:** If client connects after job already completed, immediately send the final result (not stuck in polling loop forever).
    - **Timeout:** Close WebSocket after 10 minutes if job still running (safety limit).

    **4. Register WebSocket router** in `backend/app/main.py`:
    - Import websocket router and include it (WebSocket routes in FastAPI are registered the same as HTTP routes via APIRouter)

    **Important implementation notes:**
    - Use `from celery.result import AsyncResult` to poll Celery task state
    - Celery task update_state with PROGRESS state and meta dict is how the pipeline task communicates progress (already implemented in 03-01)
    - For DB reads in WebSocket handler, use async session (same as HTTP endpoints)
    - Generate presigned URLs using s3_client.generate_presigned_url for result images
    - Import celery_app from app.workers.celery_app
  </action>
  <verify>
    cd backend && python -c "from app.api.routes.websocket import router; print('WebSocket router OK')"
    cd backend && python -c "from app.schemas.websocket import ProgressMessage, CompletionMessage, ErrorMessage; print('WS schemas OK')"
    grep "websocket" backend/app/main.py  # Router registered
    grep "STEP_DISPLAY_NAMES" backend/app/api/routes/websocket.py  # Step mapping exists
    grep "Finding your iris" backend/app/api/routes/websocket.py  # Magical names present
  </verify>
  <done>
    WebSocket endpoint at /ws/jobs/{job_id} streams real-time progress with magical step names. Authenticated via JWT query param. Handles completion (sends result URL), failure (sends classified error with suggestion), and disconnection (job continues in background). 10-minute timeout safety limit.
  </done>
</task>

<task type="auto">
  <name>Task 2: Enhance pipeline task with granular progress updates and error classification</name>
  <files>
    backend/app/workers/tasks/processing.py
  </files>
  <action>
    **1. Refine progress update granularity** in `process_iris_pipeline` task:
    - Ensure every step updates BOTH the database (ProcessingJob record) AND Celery task state (self.update_state)
    - The dual update ensures: (a) WebSocket can poll Celery state for real-time updates, (b) database has persistent state if WebSocket reconnects after disconnect
    - Progress checkpoints should be smooth: 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100
    - Each major step (segmenting, removing_reflections, enhancing) should have at least 2 progress updates (start and finish)

    **2. Enhance error classification** to ensure all error paths set appropriate fields:
    - `ValueError` from AI models (iris not detected, quality too low):
      - error_type='quality_issue'
      - error_message: Keep the message from the exception (already user-friendly from model wrappers)
      - suggestion: 'Try capturing a new photo in better lighting with your eye centered.'
    - `ConnectionError`, `TimeoutError` (S3 unavailable, network issues):
      - Let Celery autoretry handle first attempt
      - On final failure (after 1 auto-retry per user decision):
        - error_type='transient_error'
        - error_message='Processing timed out. Please try again.'
        - suggestion='Tap "Reprocess" to try again.'
    - `RuntimeError` (CUDA OOM, model crash):
      - Let Celery autoretry handle first attempt
      - On final failure:
        - error_type='server_error'
        - error_message='Something went wrong. Please try again later.'
        - suggestion='Tap "Reprocess" to try again, or try with a different photo.'
    - Any other unexpected exception:
      - error_type='server_error'
      - error_message='An unexpected error occurred.'
      - suggestion='Please try again later.'

    **3. Add on_failure handler** to the task:
    - Override `on_failure(self, exc, task_id, args, kwargs, einfo)` on RetryableProcessingTask
    - This fires when task permanently fails (all retries exhausted)
    - Update ProcessingJob in database: status='failed', error fields set based on exception type
    - Clean up any partial S3 objects created during failed processing (delete processed/{user_id}/{job_id}.* files)

    **4. Add on_retry handler** to track retry attempts:
    - Override `on_retry(self, exc, task_id, args, kwargs, einfo)`
    - Increment attempt_count on ProcessingJob in database
    - Log retry attempt with exception info

    **5. Ensure Celery update_state meta includes all fields** that WebSocket needs:
    ```python
    self.update_state(state='PROGRESS', meta={
        'step': current_step_name,       # Internal name (segmenting, etc.)
        'progress': progress_value,       # 0-100
        'job_id': job_id,
    })
    ```
    The WebSocket endpoint maps the internal step name to a display name.
  </action>
  <verify>
    cd backend && python -c "from app.workers.tasks.processing import process_iris_pipeline, RetryableProcessingTask; print('Pipeline OK')"
    grep "on_failure" backend/app/workers/tasks/processing.py  # Failure handler exists
    grep "on_retry" backend/app/workers/tasks/processing.py  # Retry handler exists
    grep "quality_issue" backend/app/workers/tasks/processing.py  # Error classification present
    grep "update_state" backend/app/workers/tasks/processing.py  # Celery state updates present
  </verify>
  <done>
    Pipeline task has granular progress updates (dual: Celery state + DB), classified error handling for all failure modes (quality, transient, server), on_failure cleanup of partial S3 objects, on_retry attempt tracking. WebSocket can poll Celery state for real-time progress, DB has persistent state for reconnection.
  </done>
</task>

</tasks>

<verification>
1. WebSocket endpoint importable and registered in main.py
2. Step name mapping contains all magical names: "Finding your iris...", "Removing reflections...", "Enhancing quality..."
3. Pipeline task updates both Celery state and database at each step
4. Error classification covers quality_issue, transient_error, server_error
5. on_failure handler cleans up partial S3 objects
6. WebSocket handles already-completed jobs (immediate result delivery)
7. WebSocket times out after 10 minutes
</verification>

<success_criteria>
- WebSocket at /ws/jobs/{job_id} accepts connections with JWT auth
- Real-time progress updates stream every 500ms during processing
- Step names are magical: "Finding your iris...", "Removing reflections...", "Enhancing quality..."
- Completion sends presigned result URL
- Failure sends classified error with friendly message and suggestion
- Job survives WebSocket disconnection (continues in Celery)
- Already-completed jobs return result immediately on connect
</success_criteria>

<output>
After completion, create `.planning/phases/03-ai-processing-pipeline/03-02-SUMMARY.md`
</output>
