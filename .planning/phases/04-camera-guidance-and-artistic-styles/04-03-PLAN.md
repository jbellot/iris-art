---
phase: 04-camera-guidance-and-artistic-styles
plan: 03
type: execute
wave: 2
depends_on: ["04-02"]
files_modified:
  - backend/app/workers/models/sd_generator.py
  - backend/app/workers/models/controlnet_processor.py
  - backend/app/workers/models/model_cache.py
  - backend/app/workers/tasks/ai_generation.py
  - backend/app/models/export_job.py
  - backend/app/schemas/exports.py
  - backend/app/services/exports.py
  - backend/app/services/watermark.py
  - backend/app/workers/tasks/hd_export.py
  - backend/app/api/routes/exports.py
  - backend/app/api/routes/styles.py
  - backend/app/main.py
  - backend/requirements.txt
  - mobile/src/types/exports.ts
  - mobile/src/services/exports.ts
  - mobile/src/hooks/useAIGeneration.ts
  - mobile/src/hooks/useHDExport.ts
  - mobile/src/screens/Styles/AIGenerateScreen.tsx
  - mobile/src/screens/Exports/HDExportScreen.tsx
  - mobile/src/screens/Styles/StylePreviewScreen.tsx
  - mobile/src/navigation/types.ts
  - mobile/src/navigation/RootNavigator.tsx
autonomous: true

must_haves:
  truths:
    - "User can generate an AI-unique artistic composition from their processed iris"
    - "User sees generation progress with magical step names while AI creates their art"
    - "User can export HD version of styled or generated art"
    - "Free exports include a visible watermark overlay; paid exports are HD without watermark"
    - "HD export runs as background Celery task with progress tracking"
  artifacts:
    - path: "backend/app/workers/models/sd_generator.py"
      provides: "SDXL Turbo wrapper for iris-to-art generation with dev-mode fallback"
      contains: "class SDXLTurboGenerator"
    - path: "backend/app/workers/tasks/ai_generation.py"
      provides: "Celery task for AI art generation"
      contains: "generate_ai_art"
    - path: "backend/app/services/watermark.py"
      provides: "Server-side watermark application for free exports"
      contains: "apply_watermark"
    - path: "backend/app/workers/tasks/hd_export.py"
      provides: "Celery task for HD upscale + watermark logic"
      contains: "export_hd_image"
    - path: "backend/app/api/routes/exports.py"
      provides: "REST API for HD export requests"
      exports: ["router"]
    - path: "mobile/src/screens/Styles/AIGenerateScreen.tsx"
      provides: "AI art generation screen with prompt and progress"
    - path: "mobile/src/screens/Exports/HDExportScreen.tsx"
      provides: "HD export screen with payment gate placeholder and download"
  key_links:
    - from: "backend/app/workers/tasks/ai_generation.py"
      to: "backend/app/workers/models/sd_generator.py"
      via: "Celery task uses SD generator for inference"
      pattern: "SDXLTurboGenerator"
    - from: "backend/app/workers/tasks/hd_export.py"
      to: "backend/app/services/watermark.py"
      via: "Export task applies watermark based on payment status"
      pattern: "apply_watermark"
    - from: "mobile/src/screens/Exports/HDExportScreen.tsx"
      to: "mobile/src/services/exports.ts"
      via: "Export screen submits HD export job via API"
      pattern: "requestHDExport"
    - from: "backend/app/api/routes/exports.py"
      to: "backend/app/workers/tasks/hd_export.py"
      via: "Export route dispatches Celery task"
      pattern: "export_hd_image"
---

<objective>
Build AI-unique art generation using Stable Diffusion and the complete HD export pipeline with server-side watermarking for free/paid differentiation.

Purpose: Users can create one-of-a-kind artistic compositions inspired by their iris patterns, and export their art in HD quality — completing the monetizable art pipeline (free = watermarked SD, paid = clean HD).

Output: SDXL Turbo backend integration, ControlNet iris edge guidance, AI generation Celery task, HD export pipeline with watermark, mobile AI generation and export screens.
</objective>

<execution_context>
@/home/jbellot/.claude/get-shit-done/workflows/execute-plan.md
@/home/jbellot/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-camera-guidance-and-artistic-styles/04-RESEARCH.md
@.planning/phases/04-camera-guidance-and-artistic-styles/04-02-SUMMARY.md
@backend/app/workers/models/model_cache.py
@backend/app/workers/tasks/style_transfer.py
@backend/app/api/routes/styles.py
@backend/app/services/watermark.py
@mobile/src/services/styles.ts
@mobile/src/hooks/useStyleTransfer.ts
@mobile/src/screens/Styles/StylePreviewScreen.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Backend SDXL Turbo generator, ControlNet processor, AI generation task, HD export pipeline, and watermark service</name>
  <files>
    backend/app/workers/models/sd_generator.py
    backend/app/workers/models/controlnet_processor.py
    backend/app/workers/models/model_cache.py
    backend/app/workers/tasks/ai_generation.py
    backend/app/models/export_job.py
    backend/app/schemas/exports.py
    backend/app/services/exports.py
    backend/app/services/watermark.py
    backend/app/workers/tasks/hd_export.py
    backend/app/api/routes/exports.py
    backend/app/api/routes/styles.py
    backend/app/main.py
    backend/requirements.txt
  </files>
  <action>
Build the Stable Diffusion art generation backend and complete HD export pipeline.

**AI Generation Models:**

1. **backend/app/workers/models/sd_generator.py** — SDXLTurboGenerator class:
   - `__init__()`: Pipeline and ControlNet references (initially None)
   - `load()`: Load SDXL Turbo pipeline from "stabilityai/sdxl-turbo" using `AutoPipelineForImage2Image.from_pretrained()` with torch_dtype=torch.float16. Enable xformers memory efficient attention if available.
   - `generate(iris_image: PIL.Image, prompt: str, control_image: PIL.Image = None, num_steps: int = 4, strength: float = 0.8) -> PIL.Image`:
     - If ControlNet loaded: use it for edge-guided composition
     - Run pipeline with guidance_scale=0.0 (Turbo doesn't need guidance), num_inference_steps=num_steps, strength=strength
     - Return generated PIL.Image at 1024x1024
   - **Dev-mode fallback:** If torch not available or CUDA not present, use OpenCV artistic filters as simulation:
     - Apply `cv2.edgePreservingFilter(image, flags=1, sigma_s=60, sigma_r=0.4)` + color shift based on prompt keywords
     - Return stylized image at 1024x1024
     - Log warning: "SDXL Turbo not available, using OpenCV simulation (dev mode)"
   - Memory management: Call `torch.cuda.empty_cache()` after generation

2. **backend/app/workers/models/controlnet_processor.py** — ControlNetProcessor class:
   - `extract_iris_edges(image: PIL.Image) -> PIL.Image`:
     - Convert to grayscale, apply Canny edge detection (thresholds 50, 150)
     - Optionally enhance iris radial patterns: detect circles with HoughCircles, strengthen detected edges
     - Return edge map as PIL.Image
   - `extract_color_map(image: PIL.Image) -> PIL.Image`:
     - Create color palette from iris: extract dominant colors using k-means clustering (k=5) on center 50% of image
     - Create abstract color map image from palette
     - Return as PIL.Image
   - **Dev-mode:** If OpenCV available (it is from Phase 3), these always work — no model needed

3. **Update backend/app/workers/models/model_cache.py**:
   - Add `_sd_generator: Optional[SDXLTurboGenerator] = None`
   - Add `get_sd_generator() -> SDXLTurboGenerator`: Lazy-load and cache
   - Add `_controlnet_processor: Optional[ControlNetProcessor] = None`
   - Add `get_controlnet_processor() -> ControlNetProcessor`: Lazy-load and cache
   - Add `clear_sd_generator()`: Unload SD model to free VRAM (important for memory management — call before loading Real-ESRGAN)

**AI Generation Celery Task:**

4. **backend/app/workers/tasks/ai_generation.py** — `generate_ai_art` task:
   - Inherit from RetryableProcessingTask, route to `high_priority` queue
   - Input: user_id, photo_id, processing_job_id (processed iris), prompt (str), style_hint (str, optional — e.g., "cosmic", "abstract")
   - This reuses the StyleJob model from 04-02 — create a StyleJob record with style_preset_id=NULL (indicates AI generation, not preset)
   - Steps with magical names:
     1. "Reading your iris patterns..." (0-10%): Load processed iris from S3
     2. "Extracting unique features..." (10-25%): Run ControlNet processor for edge and color extraction
     3. "Imagining your artwork..." (25-75%): Run SDXL Turbo generation with prompt + iris edges as control
     4. "Refining the details..." (75-90%): Save preview (256px) and full result (1024px) to S3 at `ai_art/{user_id}/{job_id}_preview.jpg` and `ai_art/{user_id}/{job_id}.jpg`
     5. "Almost done..." (90-100%): Update StyleJob in database with results
   - Build prompt from iris analysis: If no user prompt, generate default: "A stunning artistic composition inspired by the patterns and colors of a human iris, {style_hint} style, highly detailed, masterpiece"
   - Dual state updates (Celery + database) — same pattern as style_transfer.py
   - on_failure handler: S3 cleanup, error classification

**HD Export Pipeline:**

5. **backend/app/models/export_job.py** — ExportJob model:
   - Fields: `id` (UUID), `user_id` (FK), `source_type` (enum: "styled", "ai_generated", "processed"), `source_job_id` (UUID — StyleJob or ProcessingJob ID), `source_s3_key` (str — the image to upscale), `status` (enum: "pending", "processing", "completed", "failed"), `progress` (int 0-100), `current_step` (str), `celery_task_id` (str), `is_paid` (bool, default False — set True after payment verification in Phase 6), `result_s3_key` (str, nullable), `result_width` (int, nullable), `result_height` (int, nullable), `file_size_bytes` (int, nullable), `processing_time_ms` (int, nullable), `error_type` (str, nullable), `error_message` (str, nullable), `created_at`, `updated_at`
   - Create Alembic migration

6. **backend/app/schemas/exports.py** — Pydantic schemas:
   - `HDExportRequest`: source_type ("styled" | "ai_generated" | "processed"), source_job_id (UUID)
   - `ExportJobResponse`: id, status, progress, current_step, is_paid, result_url (presigned, only if completed), result_width, result_height, file_size_bytes, processing_time_ms
   - `ExportJobListResponse`: items, total

7. **backend/app/services/exports.py**:
   - `create_export_job(user_id, source_type, source_job_id)`: Look up source S3 key from StyleJob or ProcessingJob, create ExportJob, submit Celery task, return job
   - `get_export_job(job_id, user_id)`: Get job with presigned URL for result
   - `list_export_jobs(user_id, limit=20, offset=0)`: List user's exports
   - `mark_as_paid(job_id)`: Set is_paid=True (called by payment webhook in Phase 6)

8. **backend/app/services/watermark.py**:
   - `apply_watermark(image: PIL.Image, is_paid: bool) -> PIL.Image`:
     - If `is_paid`: Return image unmodified (no watermark)
     - If not paid: Apply semi-transparent watermark:
       - Draw "IrisVue" text diagonally across image at 45 degrees
       - Use PIL ImageDraw with semi-transparent white fill (alpha=80/255)
       - Font size proportional to image size (image_width / 8)
       - Repeat watermark text 3-4 times across the image in a tiled pattern
       - Also add small "Free Preview" text in bottom-right corner
     - Return watermarked image

9. **backend/app/workers/tasks/hd_export.py** — `export_hd_image` task:
   - Inherit from RetryableProcessingTask, route to `default` queue (not high_priority — export is non-urgent)
   - Steps:
     1. "Preparing for HD export..." (0-10%): Load source image from S3
     2. "Upscaling to HD..." (10-70%): Use Real-ESRGAN (via ModelCache enhancement model) for 4x upscale. If Real-ESRGAN not available (dev mode), use OpenCV Lanczos resize to 2048x2048
     3. "Applying finishing touches..." (70-85%): Check `is_paid` on ExportJob. Apply watermark via watermark service
     4. "Saving your masterpiece..." (85-100%): Save to S3 at `exports/{user_id}/{job_id}.jpg` (JPEG quality 95), update ExportJob with result_s3_key, dimensions, file_size_bytes, processing_time_ms
   - Before loading Real-ESRGAN: Call `ModelCache.clear_sd_generator()` and `ModelCache.clear_style_models()` to free VRAM
   - on_failure handler: S3 cleanup, error classification

**API Routes:**

10. **backend/app/api/routes/exports.py**:
    - `POST /api/v1/exports/hd`: Request HD export (auth required). Accepts HDExportRequest, returns ExportJobResponse
    - `GET /api/v1/exports/jobs/{job_id}`: Get export job status with presigned result URL (auth required)
    - `GET /api/v1/exports/jobs`: List user's export jobs (auth required)

11. **Update backend/app/api/routes/styles.py**:
    - Add `POST /api/v1/styles/generate`: Submit AI art generation job (auth required). Accepts: photo_id, processing_job_id, prompt (optional str), style_hint (optional str). Returns StyleJobResponse (reuses same response schema)

12. **Update backend/app/main.py**: Register exports router at `/api/v1/exports`

13. **Update backend/requirements.txt**: Add `diffusers>=0.30.0`, `transformers>=4.40.0`, `accelerate>=0.30.0`, `controlnet_aux` (optional — can skip if using custom ControlNet preprocessing from controlnet_processor.py)

**Important implementation details:**
- Dev-mode fallback is critical: SDXL Turbo requires CUDA GPU. OpenCV fallback must produce a visually distinct artistic image (not just the input passed through)
- For the OpenCV dev-mode fallback in sd_generator.py: combine edgePreservingFilter with color quantization and a color overlay to produce something that looks "generated"
- ExportJob.is_paid defaults to False — in Phase 6, payment verification will call `mark_as_paid()` before the export task checks the flag. For now, all exports get watermarks. This is correct for MVP.
- The tiled diagonal watermark pattern should be robust enough that simple cropping doesn't remove it
- Memory management between SD and Real-ESRGAN is critical: these models compete for VRAM. Always unload one before loading the other.
  </action>
  <verify>
    - `cd backend && python -c "from app.workers.models.sd_generator import SDXLTurboGenerator; print('SD OK')"` succeeds
    - `cd backend && python -c "from app.workers.tasks.ai_generation import generate_ai_art; print('AI Task OK')"` succeeds
    - `cd backend && python -c "from app.services.watermark import apply_watermark; print('Watermark OK')"` succeeds
    - `cd backend && python -c "from app.workers.tasks.hd_export import export_hd_image; print('Export Task OK')"` succeeds
    - `cd backend && python -c "from app.api.routes.exports import router; print('Exports Router OK')"` succeeds
    - `grep "exports" backend/app/main.py` confirms router registered
    - `grep "generate" backend/app/api/routes/styles.py` confirms AI generation endpoint added
    - Alembic migration for export_jobs table exists
  </verify>
  <done>
    - SDXLTurboGenerator wraps SDXL Turbo with ControlNet and dev-mode OpenCV fallback
    - ControlNetProcessor extracts iris edges and color maps for guided generation
    - generate_ai_art Celery task creates unique art from iris patterns
    - ExportJob model tracks HD export requests with is_paid flag
    - Watermark service applies tiled diagonal watermark for free exports
    - export_hd_image Celery task upscales and applies watermark
    - REST API endpoints for AI generation and HD export
  </done>
</task>

<task type="auto">
  <name>Task 2: Mobile AI generation screen, HD export screen, and integration with existing style preview</name>
  <files>
    mobile/src/types/exports.ts
    mobile/src/services/exports.ts
    mobile/src/hooks/useAIGeneration.ts
    mobile/src/hooks/useHDExport.ts
    mobile/src/screens/Styles/AIGenerateScreen.tsx
    mobile/src/screens/Exports/HDExportScreen.tsx
    mobile/src/screens/Styles/StylePreviewScreen.tsx
    mobile/src/navigation/types.ts
    mobile/src/navigation/RootNavigator.tsx
  </files>
  <action>
Build mobile screens for AI art generation and HD export, plus integrate export flow into existing style preview.

**Types:**

1. **mobile/src/types/exports.ts**:
   - `ExportJob`: id, status, progress, currentStep, isPaid, resultUrl, resultWidth, resultHeight, fileSizeBytes, processingTimeMs
   - `HDExportRequest`: sourceType ('styled' | 'ai_generated' | 'processed'), sourceJobId (string)

**API Service:**

2. **mobile/src/services/exports.ts**:
   - `requestHDExport(request: HDExportRequest)`: POST `/api/v1/exports/hd`, returns ExportJob
   - `getExportJob(jobId)`: GET `/api/v1/exports/jobs/{jobId}`, returns ExportJob
   - `getExportJobs()`: GET `/api/v1/exports/jobs`, returns list
   - `generateAIArt(photoId, processingJobId, prompt?, styleHint?)`: POST `/api/v1/styles/generate`, returns StyleJob (reuses style job type)

**Hooks:**

3. **mobile/src/hooks/useAIGeneration.ts**:
   - `useAIGeneration(photoId, processingJobId)` hook
   - `generate(prompt?, styleHint?)`: Submit AI generation job, track in style store
   - `activeJob`: Current AI generation job (from style store — AI generation uses StyleJob model on backend)
   - Uses useJobProgress hook for WebSocket progress tracking
   - `isGenerating`: boolean derived from activeJob status

4. **mobile/src/hooks/useHDExport.ts**:
   - `useHDExport()` hook
   - `requestExport(sourceType, sourceJobId)`: Submit HD export request, track progress
   - `activeExport`: Current export job
   - Uses useJobProgress hook for progress
   - `downloadResult(resultUrl)`: Download result image to device gallery using react-native-fs or CameraRoll
   - `isExporting`: boolean

**Screens:**

5. **mobile/src/screens/Styles/AIGenerateScreen.tsx**:
   - Route params: `photoId`, `processingJobId`, `originalImageUrl`
   - Layout:
     - Source iris image thumbnail at top
     - Optional prompt input (TextInput, placeholder: "Describe your vision... (optional)")
     - Style hint picker: Row of tappable chips for "Cosmic", "Abstract", "Watercolor", "Oil Painting", "Geometric", "Minimalist" — tapping one sets styleHint
     - "Generate" button (large, prominent) — calls `generate(prompt, styleHint)`
   - **While generating:**
     - Disable generate button, show progress bar with magical step name from WebSocket
     - Show animated placeholder (shimmer/pulse on the source image area)
   - **When complete:**
     - Show result using ProgressiveImage (preview URL first, then full URL)
     - Show source iris small thumbnail next to result for comparison
     - Actions: "Generate Again" (new generation), "Export HD" (navigate to HDExportScreen), "Save" (save 1024px version to device), "Share"
   - **On error:** Show error message with "Try Again" button

6. **mobile/src/screens/Exports/HDExportScreen.tsx**:
   - Route params: `sourceType` ('styled' | 'ai_generated' | 'processed'), `sourceJobId`, `previewImageUrl` (the 1024px styled/generated image)
   - Layout:
     - Preview image at top (the styled/generated art at current resolution)
     - HD info section: "Export at 2048x2048 HD resolution"
     - **Payment gate placeholder (Phase 6 adds real payment):**
       - Show "Free Export" badge with note: "Free exports include a watermark"
       - "Export HD (Free with watermark)" button — submits export job with is_paid=false
       - Grayed out "Export HD without watermark — 4.99 EUR" button (placeholder — not functional until Phase 6)
     - **While exporting:** Progress bar with step names from WebSocket
     - **When complete:**
       - Show result image (watermarked for free users)
       - "Download to Device" button — save to CameraRoll
       - "Share" button
       - File size and resolution info: "2048x2048 • {size} MB"
   - **On error:** Show error with "Try Again"

7. **Update mobile/src/screens/Styles/StylePreviewScreen.tsx**:
   - Add "Export HD" button to actions bar (alongside "Try Another Style", "Save", "Share")
   - "Export HD" navigates to HDExportScreen with sourceType='styled', sourceJobId=current style job ID, previewImageUrl=result URL
   - Add "Generate AI Art" button that navigates to AIGenerateScreen (alternative path from styled result to AI generation)

**Navigation:**

8. **Update mobile/src/navigation/types.ts**:
   - Add `AIGenerate` route: `{ photoId: string, processingJobId: string, originalImageUrl: string }`
   - Add `HDExport` route: `{ sourceType: 'styled' | 'ai_generated' | 'processed', sourceJobId: string, previewImageUrl: string }`

9. **Update mobile/src/navigation/RootNavigator.tsx**:
   - Register AIGenerate and HDExport screens in MainStack

**Important implementation details:**
- AI generation reuses StyleJob on the backend (with style_preset_id=NULL) — the mobile side reuses the style store and WebSocket progress patterns
- The payment gate is a placeholder: all exports currently get watermarks (is_paid=false). Phase 6 will wire up RevenueCat payment to set is_paid=true before export
- "Download to Device" uses CameraRoll.save() (same pattern as ProcessingResultScreen save action)
- The HD export WebSocket progress uses the same useJobProgress hook from Phase 3
- For "Generate Again" on AIGenerateScreen: reset state and allow user to modify prompt before regenerating
- Style hint chips should visually indicate selected state (highlighted background)
  </action>
  <verify>
    - `cd mobile && npx tsc --noEmit` passes
    - `grep -r "AIGenerateScreen" mobile/src/navigation/RootNavigator.tsx` confirms registration
    - `grep -r "HDExportScreen" mobile/src/navigation/RootNavigator.tsx` confirms registration
    - `grep -r "api/v1/exports" mobile/src/services/exports.ts` confirms API integration
    - `grep -r "Export HD" mobile/src/screens/Styles/StylePreviewScreen.tsx` confirms export button added
    - All screen files exist in correct directories
  </verify>
  <done>
    - AIGenerateScreen lets user enter optional prompt and style hint, generates unique AI art
    - HDExportScreen shows payment gate placeholder and watermarked free export flow
    - StylePreviewScreen updated with "Export HD" and "Generate AI Art" buttons
    - Export API service connects to backend endpoints
    - useAIGeneration and useHDExport hooks manage generation and export workflows
    - Navigation routes registered for AIGenerate and HDExport
  </done>
</task>

</tasks>

<verification>
1. Backend: AI generation models import successfully (sd_generator, controlnet_processor)
2. Backend: AI generation and HD export Celery tasks import and register
3. Backend: Watermark service applies tiled diagonal watermark
4. Backend: Export routes registered in main.py
5. Backend: Alembic migration for export_jobs table
6. Mobile: `cd mobile && npx tsc --noEmit` passes
7. Mobile: AIGenerate and HDExport screens registered in navigation
8. Mobile: StylePreviewScreen has "Export HD" button
9. Integration: AI generation uses existing WebSocket progress infrastructure
10. Integration: Export pipeline uses Real-ESRGAN (or dev-mode Lanczos) + watermark
</verification>

<success_criteria>
- AI art generation produces unique compositions from iris images (dev-mode: OpenCV artistic filter)
- HD export pipeline upscales to 2048x2048 with server-side watermark for free users
- Mobile AI generation screen allows optional prompt input and style hint selection
- Mobile HD export screen shows watermarked result with download capability
- Payment gate placeholder correctly shows "free with watermark" vs "paid without watermark"
- All components reuse existing patterns (WebSocket progress, Celery tasks, style store)
</success_criteria>

<output>
After completion, create `.planning/phases/04-camera-guidance-and-artistic-styles/04-03-SUMMARY.md`
</output>
